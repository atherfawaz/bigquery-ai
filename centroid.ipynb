{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":110281,"databundleVersionId":13391012,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup and test BQ connection\n\n## Pre-requisites:\n- enable vertex ai api\n- create a new vertex ai connection object in BQ\n- create an instance of the gemini embedding model using the vertex ai connection\n```sql \nCREATE OR REPLACE MODEL `graphite-cell-472319-d2.amazon_esci.gemini_embedding`\nREMOTE WITH CONNECTION `graphite-cell-472319-d2.US.vertex-ai`\nOPTIONS (ENDPOINT = 'gemini-embedding-001');\n```","metadata":{}},{"cell_type":"code","source":"# Cloud Storage\nfrom google.cloud import storage\nstorage_client = storage.Client(project='graphite-cell-472319-d2')\n\n# BigQuery\nfrom google.cloud import bigquery\nbigquery_client = bigquery.Client(project='graphite-cell-472319-d2')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T16:17:39.547674Z","iopub.execute_input":"2025-09-19T16:17:39.548062Z","iopub.status.idle":"2025-09-19T16:17:59.250633Z","shell.execute_reply.started":"2025-09-19T16:17:39.548031Z","shell.execute_reply":"2025-09-19T16:17:59.249656Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load dataset and upload to BQ tables","metadata":{}},{"cell_type":"code","source":"# Install deps\nimport kagglehub\nfrom kagglehub import KaggleDatasetAdapter\nimport pandas as pd\nfrom google.cloud import bigquery\n\n# ---- CONFIGURE THESE ----\nPROJECT_ID = \"graphite-cell-472319-d2\"   # <-- replace with your Kaggle BigQuery project ID\nDATASET_ID = \"amazon_esci\"           # BigQuery dataset name\n# -------------------------\n\n# File paths exactly as they exist in the dataset\nexamples_fp = \"shopping_queries_dataset/shopping_queries_dataset_examples.parquet\"\nproducts_fp = \"shopping_queries_dataset/shopping_queries_dataset_products.parquet\"\nsources_fp  = \"shopping_queries_dataset/shopping_queries_dataset_sources.csv\"\n\n# Load files via kagglehub\ndf_examples = kagglehub.load_dataset(KaggleDatasetAdapter.PANDAS, \"marquis03/amazon-esci\", examples_fp)\ndf_products = kagglehub.load_dataset(KaggleDatasetAdapter.PANDAS, \"marquis03/amazon-esci\", products_fp)\ndf_sources  = kagglehub.load_dataset(KaggleDatasetAdapter.PANDAS, \"marquis03/amazon-esci\", sources_fp)\n\nprint(\"Examples:\", df_examples.shape)\nprint(\"Products:\", df_products.shape)\nprint(\"Sources:\", df_sources.shape)\n\nprint(df_examples.head())\n\n# Init BigQuery client\nclient = bigquery.Client(project=PROJECT_ID)\n\n# Create dataset if it doesn't exist\ndataset_ref = bigquery.Dataset(f\"{PROJECT_ID}.{DATASET_ID}\")\ntry:\n    client.get_dataset(dataset_ref)\n    print(f\"Dataset {DATASET_ID} already exists\")\nexcept Exception:\n    dataset_ref.location = \"US\"\n    client.create_dataset(dataset_ref)\n    print(f\"Created dataset {DATASET_ID}\")\n\n# Helper to upload DataFrame to BigQuery\ndef upload_to_bq(df: pd.DataFrame, table_name: str):\n    table_id = f\"{PROJECT_ID}.{DATASET_ID}.{table_name}\"\n    job_config = bigquery.LoadJobConfig(\n        autodetect=True,\n        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE\n    )\n    job = client.load_table_from_dataframe(df, table_id, job_config=job_config)\n    job.result()\n    print(f\"Uploaded {len(df)} rows to {table_id}\")\n\n# Upload the three tables\nupload_to_bq(df_examples, \"shopping_queries_dataset_examples\")\nupload_to_bq(df_products, \"shopping_queries_dataset_products\")\nupload_to_bq(df_sources, \"shopping_queries_dataset_sources\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T17:30:02.336775Z","iopub.execute_input":"2025-09-17T17:30:02.337124Z","iopub.status.idle":"2025-09-17T17:30:58.870354Z","shell.execute_reply.started":"2025-09-17T17:30:02.337101Z","shell.execute_reply":"2025-09-17T17:30:58.868943Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Audit Amazon ESCI Dataset","metadata":{}},{"cell_type":"code","source":"query = \"\"\"\n    SELECT * FROM `graphite-cell-472319-d2.amazon_esci.shopping_queries_dataset_examples` LIMIT 10\n\"\"\"\nquery_job = bigquery_client.query(query)  \nresults = query_job.result().to_dataframe()\n\nprint(results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T17:21:03.169722Z","iopub.execute_input":"2025-09-17T17:21:03.169999Z","iopub.status.idle":"2025-09-17T17:21:04.011827Z","shell.execute_reply.started":"2025-09-17T17:21:03.169976Z","shell.execute_reply":"2025-09-17T17:21:04.010419Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Embed all queries with batched inference","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\nfrom tqdm.notebook import tqdm\n\ndef run_batched_embedding(\n    project_id: str,\n    dataset_id: str,\n    model_id: str,\n    source_query: str,\n    dest_table: str,\n    batch_size: int = 10000,\n):\n    \"\"\"\n    Run batched embedding generation with ML.GENERATE_EMBEDDING in BigQuery.\n    \n    Args:\n        project_id: GCP project ID\n        dataset_id: BigQuery dataset ID\n        model_id: Full model path for embedding (e.g. \"project.dataset.model\")\n        source_query: SQL query that must output a column named 'content'\n        dest_table: Destination table name (without project/dataset)\n        batch_size: Number of rows per batch\n    \"\"\"\n\n    client = bigquery.Client(project=project_id)\n    dest_full_table = f\"{project_id}.{dataset_id}.{dest_table}\"\n\n    # Count rows to figure out number of batches\n    count_query = f\"SELECT COUNT(*) as total FROM ({source_query})\"\n    total_rows = client.query(count_query).result().to_dataframe()[\"total\"].iloc[0]\n    total_batches = (total_rows + batch_size - 1) // batch_size\n\n    print(f\"Total rows: {total_rows}, Batch size: {batch_size}, Total batches: {total_batches}\")\n\n    for i in tqdm(range(total_batches), desc=\"Embedding batches\"):\n        offset = i * batch_size\n\n        # Get i-th batch of queries\n        batch_query = f\"\"\"\n        WITH base AS (\n          SELECT content\n          FROM ({source_query})\n          ORDER BY content\n          LIMIT {batch_size} OFFSET {offset}\n        ),\n        emb AS (\n          SELECT *\n          FROM ML.GENERATE_EMBEDDING(\n            MODEL `{model_id}`,\n            (SELECT content FROM base),\n            STRUCT(TRUE AS flatten_json_output, 'RETRIEVAL_DOCUMENT' AS task_type)\n          )\n        )\n        SELECT \n          base.content,\n          emb.ml_generate_embedding_result,\n          emb.ml_generate_embedding_statistics,\n          emb.ml_generate_embedding_status\n        FROM base\n        JOIN emb\n        USING (content)\n        \"\"\"\n\n        # Push batch result to the destination table\n        job_config = bigquery.QueryJobConfig(\n            destination=dest_full_table,\n            write_disposition=\"WRITE_TRUNCATE\" if i == 0 else \"WRITE_APPEND\"\n        )\n\n        job = client.query(batch_query, job_config=job_config)\n        job.result()  # wait for completion\n\n    print(f\"âœ… Finished embedding into {dest_full_table}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T19:31:35.634964Z","iopub.execute_input":"2025-09-17T19:31:35.635886Z","iopub.status.idle":"2025-09-17T19:31:35.646099Z","shell.execute_reply.started":"2025-09-17T19:31:35.635853Z","shell.execute_reply":"2025-09-17T19:31:35.645159Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"run_batched_embedding(\n    project_id=\"graphite-cell-472319-d2\",\n    dataset_id=\"amazon_esci\",\n    model_id=\"graphite-cell-472319-d2.amazon_esci.gemini_embedding\",\n    source_query=\"\"\"\n        SELECT DISTINCT LOWER(TRIM(query)) AS content\n        FROM `graphite-cell-472319-d2.amazon_esci.shopping_queries_dataset_examples`\n    \"\"\",\n    dest_table=\"query_embeddings\",\n    batch_size=10000\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T17:40:45.923734Z","iopub.execute_input":"2025-09-17T17:40:45.924196Z","iopub.status.idle":"2025-09-17T17:52:20.686200Z","shell.execute_reply.started":"2025-09-17T17:40:45.924162Z","shell.execute_reply":"2025-09-17T17:52:20.685158Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Filter out Products to Embed \n\nFilter: `small_version == 1 + product_locale == 'us'`","metadata":{}},{"cell_type":"code","source":"# from google.cloud import bigquery\n\nclient = bigquery.Client(project=\"graphite-cell-472319-d2\")\n\n# Consolidate the key textual data (title, description, bullet points) for each product into a single, clean field.\nquery = \"\"\"\nCREATE OR REPLACE TABLE `graphite-cell-472319-d2.amazon_esci.products_to_embed`\nAS\nSELECT \n  product_id,\n  ANY_VALUE(CONCAT(\n      'PRODUCT_TITLE: ', IFNULL(product_title, '...'), '\\\\n\\\\n',\n      'PRODUCT_BULLET_POINTS: ', IFNULL(product_bullet_point, '...'), '\\\\n\\\\n',\n      'PRODUCT_DESCRIPTION: ', IFNULL(product_description, '...')\n  )) AS content\nFROM `graphite-cell-472319-d2.amazon_esci.shopping_queries_dataset_examples`\nJOIN `graphite-cell-472319-d2.amazon_esci.shopping_queries_dataset_products`\nUSING (product_id, product_locale)\nWHERE product_locale = 'us'\n  AND small_version = 1\nGROUP BY product_id\n\"\"\"\n\njob = client.query(query)\njob.result()  # Waits for the job to finish\nprint(\"Table created: graphite-cell-472319-d2.amazon_esci.products_to_embed\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-17T18:15:13.590795Z","iopub.execute_input":"2025-09-17T18:15:13.591621Z","iopub.status.idle":"2025-09-17T18:15:27.862287Z","shell.execute_reply.started":"2025-09-17T18:15:13.591584Z","shell.execute_reply":"2025-09-17T18:15:27.861285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_preview = client.query(\n    \"SELECT * FROM `graphite-cell-472319-d2.amazon_esci.products_to_embed` LIMIT 5\"\n).to_dataframe()\n\ndf_preview","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Embed all products in batched inference\n> **Warning**: takes upto 4 hours to run on whole filtered dataset (482k embeddings)\n","metadata":{}},{"cell_type":"code","source":"run_batched_embedding(\n    project_id=\"graphite-cell-472319-d2\",\n    dataset_id=\"amazon_esci\",\n    model_id=\"graphite-cell-472319-d2.amazon_esci.gemini_embedding\",\n    source_query=\"\"\"\n        SELECT product_id, content\n        FROM `graphite-cell-472319-d2.amazon_esci.products_to_embed`\n    \"\"\",\n    dest_table=\"product_embeddings_test\",\n    batch_size=10000\n)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Calculate NDCG with baseline vector search\nMeasure the performance of the general-purpose embeddings using NDCG metric.\n\nWe converted the ECSI labels to their numerical equivalents in line with original [papers](https://arxiv.org/pdf/2206.06588) of the dataset.\n| Label | Relevance Score |\n| :---: | :-------------: |\n|   E   |       1.0       |\n|   S   |       0.1       |\n|   C   |      0.01       |\n|   I   |       0.0       |","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Initialize client\nclient = bigquery.Client(project=\"graphite-cell-472319-d2\")\n\n# Full NDCG query\nndcg_query = \"\"\"\n-- Step 1: Aggregate labels\n-- Weight ESCI labels for every (query, product) pair\nWITH Examples_Aggregated AS (\n  SELECT\n    query,\n    product_id,\n    AVG(CASE\n          WHEN esci_label = \"E\" THEN 1.0\n          WHEN esci_label = \"S\" THEN 0.1\n          WHEN esci_label = \"C\" THEN 0.01\n          WHEN esci_label = \"I\" THEN 0.0\n        END) AS relevance\n  FROM `graphite-cell-472319-d2.amazon_esci.shopping_queries_dataset_examples`\n  WHERE product_locale = \"us\"\n    AND small_version = 1\n  GROUP BY query, product_id\n),\n\n-- Step 2: Join embeddings\n-- Get query and product embeddings  \nEvaluationSet AS (\n  SELECT\n    ex.query,\n    ex.relevance,\n    qe.ml_generate_embedding_result AS query_embedding,\n    pe.ml_generate_embedding_result AS product_embedding\n  FROM Examples_Aggregated ex\n  JOIN `graphite-cell-472319-d2.amazon_esci.query_embeddings` qe\n    ON ex.query = qe.content\n  JOIN `graphite-cell-472319-d2.amazon_esci.product_embeddings` pe\n    ON ex.product_id = pe.product_id\n),\n\n-- Step 3: Distance\n-- Calculate cosine distance between query and product embeddings\nBaseResults AS (\n  SELECT\n    query,\n    relevance,\n    COSINE_DISTANCE(query_embedding, product_embedding) AS distance\n  FROM EvaluationSet\n),\n\n-- Step 4: DCG\nDCG_Calc AS (\n  SELECT\n    query,\n    SUM(relevance / LOG(1 + rank, 2)) AS dcg\n  FROM (\n    SELECT\n      query,\n      relevance,\n      ROW_NUMBER() OVER(PARTITION BY query ORDER BY distance ASC) AS rank\n    FROM BaseResults\n  )\n  GROUP BY query\n),\n\n-- Step 5: IDCG\nIDCG_Calc AS (\n  SELECT\n    query,\n    SUM(relevance / LOG(1 + rank, 2)) AS idcg\n  FROM (\n    SELECT\n      query,\n      relevance,\n      ROW_NUMBER() OVER(PARTITION BY query ORDER BY relevance DESC) AS rank\n    FROM BaseResults\n  )\n  GROUP BY query\n),\n\n-- Step 6: NDCG\nFinalNDCG AS (\n  SELECT\n    d.query,\n    SAFE_DIVIDE(d.dcg, i.idcg) AS ndcg\n  FROM DCG_Calc d\n  JOIN IDCG_Calc i\n    ON d.query = i.query\n)\n\n-- Final Result\nSELECT\n  COUNT(query) AS num_queries_evaluated,\n  AVG(ndcg) AS mean_ndcg\nFROM FinalNDCG;\n\"\"\"\n\n# Run query\njob = client.query(ndcg_query)\nresult = job.result().to_dataframe()\n\n# Print result\nprint(result)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T22:31:07.291122Z","iopub.execute_input":"2025-09-19T22:31:07.291496Z","iopub.status.idle":"2025-09-19T22:31:42.143598Z","shell.execute_reply.started":"2025-09-19T22:31:07.291470Z","shell.execute_reply":"2025-09-19T22:31:42.142521Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate centroid vectors for each query\nCalculate a centroid vector for each query based on users interactions with the products post the search.\n\nBecause the dataset only contain ESCI labels, we will assume the following Add-To-Cart weights for each:\n| Label | Add to Cart (ATC) Range |\n| :---: | :---------------------: |\n|   E   |      10,000-99,999      |\n|   S   |       1,000-9,999       |\n|   C   |         100-999         |\n|   I   |          0-10           |\n","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\nclient = bigquery.Client(project=\"graphite-cell-472319-d2\")\n\ncentroid_query = r'''\n-- JavaScript UDAF to aggregate embeddings with their weight and return a normalized centroid of them\nCREATE TEMPORARY AGGREGATE FUNCTION GET_EMBEDDING_CENTROID(sku_embedding ARRAY<FLOAT64>, atc FLOAT64)\n  RETURNS ARRAY<FLOAT64>\n  LANGUAGE js\n  AS r\"\"\"\n\n  export function initialState() {\n    return { sumVector: null };\n  }\n\n  export function aggregate(state, sku_embedding, atc) {\n    const weight = atc;\n    if (!sku_embedding || sku_embedding.length === 0 || weight <= 0) {\n      return;\n    }\n\n    if (state.sumVector === null) {\n      state.sumVector = sku_embedding.map(num => num * weight);\n    } else {\n      for (let i = 0; i < state.sumVector.length; i++) {\n        state.sumVector[i] += sku_embedding[i] * weight;\n      }\n    }\n  }\n\n  export function merge(state, partialState) {\n    if (!partialState.sumVector) {\n      return;\n    }\n\n    if (state.sumVector === null) {\n      state.sumVector = partialState.sumVector;\n    } else {\n      for (let i = 0; i < state.sumVector.length; i++) {\n        state.sumVector[i] += partialState.sumVector[i];\n      }\n    }\n  }\n\n  export function finalize(state) {\n    if (!state.sumVector || state.sumVector.length === 0) {\n      return [];\n    }\n\n    // Normalize the vector\n    const vecLength = Math.sqrt(state.sumVector.reduce((acc, num) => acc + num * num, 0));\n    if (vecLength === 0) {\n      return [];\n    }\n    return state.sumVector.map(num => num / vecLength);\n  }\n\n\"\"\";\n\n-- JavaScript UDF to calculate a standard deviation on a weighted input  \nCREATE TEMPORARY FUNCTION StandardDeviation(arr ARRAY<STRUCT<distance FLOAT64, weight FLOAT64>>)\nRETURNS FLOAT64\nLANGUAGE js AS \"\"\"\nif (arr.length === 0) {\n  return 0;\n}\n\nconst weight_sum = arr.reduce((acc, num) => acc + num.weight, 0);\nconst mean = arr.reduce((acc, num) => acc + num.weight * num.distance, 0) / weight_sum;\nconst sdv = arr.reduce((acc, num) => acc + Math.pow(num.distance - mean, 2) * num.weight, 0) / weight_sum;\nreturn Math.sqrt(sdv);\n\"\"\";\n\nCREATE OR REPLACE TABLE `graphite-cell-472319-d2.amazon_esci.centroid_vectors`\nAS\n\nWITH\n\n-- Assume the number of ATC events on each (query, product) based on the ESCI label\n  product_query_actions AS (\n    SELECT query, \n           product_id,\n           (CASE\n              WHEN esci_label = \"E\" THEN CAST(FLOOR(RAND() * (99999 - 10000 + 1)) + 10000 AS INT64)\n              WHEN esci_label = \"S\" THEN CAST(FLOOR(RAND() * (9999 - 1000 + 1)) + 1000 AS INT64)\n              WHEN esci_label = \"C\" THEN CAST(FLOOR(RAND() * (999 - 100 + 1)) + 100 AS INT64)\n              WHEN esci_label = \"I\" THEN CAST(FLOOR(RAND() * (10 - 0 + 1)) + 0 AS INT64)\n           END) AS atc,\n    FROM `graphite-cell-472319-d2.amazon_esci.shopping_queries_dataset_examples`\n    WHERE TRUE\n      AND small_version = 1\n      AND product_locale = \"us\"\n  ),\n  \n-- Normalize number of ATC\n  normalized_actions AS (\n    SELECT query, \n           product_id, \n           100 * atc / SUM(atc) OVER (PARTITION BY query) AS normalized_atc\n    FROM product_query_actions\n    WHERE atc > 0\n    GROUP BY query, product_id, atc\n  ),\n  \n-- Calculate initial centroid of each query (include all products)\n  query_centroid AS (\n    SELECT\n      na.query,\n      GET_EMBEDDING_CENTROID(pe.ml_generate_embedding_result, na.normalized_atc) AS centroid\n    FROM normalized_actions AS na\n    JOIN `graphite-cell-472319-d2.amazon_esci.product_embeddings` AS pe ON na.product_id = pe.product_id\n    GROUP BY query\n    HAVING ARRAY_LENGTH(centroid) > 0\n  ),\n\n-- Check the distance of each product from the intial query centroid\n  product_distance AS (\n    SELECT\n      na.query,\n      na.product_id,\n      na.normalized_atc,\n      pe.ml_generate_embedding_result AS product_embedding,\n      qc.centroid,\n      ML.DISTANCE(qc.centroid, pe.ml_generate_embedding_result, \"COSINE\") / 2 AS distance\n    FROM normalized_actions AS na\n    JOIN `graphite-cell-472319-d2.amazon_esci.product_embeddings` AS pe ON na.product_id = pe.product_id\n    JOIN query_centroid AS qc ON na.query = qc.query\n  ),\n\n-- Calculate standard deviation and mean of products distances from the initial centroid \n  query_aggregations AS (\n    SELECT query, \n           StandardDeviation(ARRAY_AGG(STRUCT(distance, normalized_atc))) AS sdv,\n           SUM(distance * normalized_atc) / SUM(normalized_atc) AS mean\n    FROM product_distance\n    GROUP BY ALL\n    HAVING sdv > 0\n  ),\n\n-- Filter outliers products\n  filtered_actions AS (\n    SELECT query, \n           product_id, \n           normalized_atc, \n           product_embedding\n    FROM product_distance\n    JOIN query_aggregations USING (query)\n    WHERE (distance - mean) / sdv <= 1.5\n  ),\n\n-- Calculate the final sanitized centroid for each query \n  sanitized_centroid AS (\n    SELECT\n      query,\n      GET_EMBEDDING_CENTROID(product_embedding, normalized_atc) AS centroid\n    FROM filtered_actions\n    GROUP BY query\n  )\n  \nSELECT query, \n       centroid\nFROM sanitized_centroid\n'''\n\n# Run the query to create the table\njob = client.query(centroid_query)\njob.result()  # wait for completion\n\nprint(\"âœ… centroid_vectors table created.\")\n\n# Preview the results\npreview_df = client.query(\"\"\"\n    SELECT * \n    FROM `graphite-cell-472319-d2.amazon_esci.centroid_vectors`\n    LIMIT 5\n\"\"\").to_dataframe()\n\nprint(preview_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-18T21:09:44.977609Z","iopub.execute_input":"2025-09-18T21:09:44.977996Z","iopub.status.idle":"2025-09-18T21:12:10.251246Z","shell.execute_reply.started":"2025-09-18T21:09:44.977965Z","shell.execute_reply":"2025-09-18T21:12:10.250269Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Calculate NDCG with centroid vector search\nEvaluate the new centroid vector using NDCG metric (Using same ESCI weights as mentioned above)","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\n# Initialize BigQuery client\nbqclient = bigquery.Client(project=\"graphite-cell-472319-d2\")\n\n# NDCG query for centroid vectors\nquery = \"\"\"\n-- Step 1: Aggregate labels\n-- Weight ESCI labels for every (query, product) pair\nWITH Examples_Aggregated AS (\n  SELECT\n    query,\n    product_id,\n    AVG(\n      CASE\n        WHEN esci_label = \"E\" THEN 1.0\n        WHEN esci_label = \"S\" THEN 0.1\n        WHEN esci_label = \"C\" THEN 0.01\n        WHEN esci_label = \"I\" THEN 0.0\n      END\n    ) AS relevance\n  FROM `graphite-cell-472319-d2.amazon_esci.shopping_queries_dataset_examples`\n  WHERE product_locale = \"us\"\n    AND small_version = 1\n  GROUP BY query, product_id\n),\n\n-- Step 2: Join embeddings\n-- Get query and product embeddings\nEvaluationSet AS (\n  SELECT\n    ex.query,\n    ex.relevance,\n    qe.centroid AS query_embedding,\n    pe.ml_generate_embedding_result AS product_embedding\n  FROM Examples_Aggregated ex\n  JOIN `graphite-cell-472319-d2.amazon_esci.centroid_vectors` qe\n    ON ex.query = qe.query\n  JOIN `graphite-cell-472319-d2.amazon_esci.product_embeddings` pe\n    ON ex.product_id = pe.product_id\n),\n\n-- Step 3: Compute distances\n-- Calculate cosine distance between query and product embeddings \nBaseResults AS (\n  SELECT\n    query,\n    relevance,\n    COSINE_DISTANCE(query_embedding, product_embedding) AS distance\n  FROM EvaluationSet\n),\n\n-- Step 4: Compute DCG\nDCG_Calc AS (\n  SELECT\n    query,\n    SUM(relevance / LOG(1 + rank, 2)) AS dcg\n  FROM (\n    SELECT\n      query,\n      relevance,\n      ROW_NUMBER() OVER (PARTITION BY query ORDER BY distance ASC) AS rank\n    FROM BaseResults\n  )\n  GROUP BY query\n),\n\n-- Step 5: Compute IDCG (ideal DCG)\nIDCG_Calc AS (\n  SELECT\n    query,\n    SUM(relevance / LOG(1 + rank, 2)) AS idcg\n  FROM (\n    SELECT\n      query,\n      relevance,\n      ROW_NUMBER() OVER (PARTITION BY query ORDER BY relevance DESC) AS rank\n    FROM BaseResults\n  )\n  GROUP BY query\n),\n\n-- Step 6: Normalize DCG\nFinalNDCG AS (\n  SELECT\n    d.query,\n    SAFE_DIVIDE(d.dcg, i.idcg) AS ndcg\n  FROM DCG_Calc d\n  JOIN IDCG_Calc i\n    ON d.query = i.query\n)\n\n-- Final Result\nSELECT\n  COUNT(query) AS num_queries_evaluated,\n  AVG(ndcg) AS mean_ndcg\nFROM FinalNDCG;\n\"\"\"\n\n# Run query\njob = bqclient.query(query)\nresult = job.result().to_dataframe()\n\n# Print results\nprint(\"Number of queries evaluated:\", result[\"num_queries_evaluated\"].iloc[0])\nprint(\"Mean NDCG:\", result[\"mean_ndcg\"].iloc[0])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T22:32:02.776209Z","iopub.execute_input":"2025-09-19T22:32:02.776777Z","iopub.status.idle":"2025-09-19T22:32:36.750450Z","shell.execute_reply.started":"2025-09-19T22:32:02.776750Z","shell.execute_reply":"2025-09-19T22:32:36.749505Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate Vector Index over product search space","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\nclient = bigquery.Client(project=\"graphite-cell-472319-d2\")\n\ncreate_index_query = \"\"\"\nCREATE VECTOR INDEX `graphite-cell-472319-d2.amazon_esci.product_embeddings_index`\nON `graphite-cell-472319-d2.amazon_esci.product_embeddings`(ml_generate_embedding_result)\nOPTIONS(\n  index_type = 'IVF',\n  distance_type = 'COSINE',\n  ivf_options = '{\"num_lists\": 100}'\n)\n\"\"\"\n\njob = client.query(create_index_query)\njob.result()\nprint(\"âœ… Vector index created successfully with num_lists=100\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sample search run on baseline","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\nclient = bigquery.Client(project=\"graphite-cell-472319-d2\")\n\n# hardcoded query for testing purposes\nsearch_text = \"rc drone without camera\"\n\n# return top 20 search results\ntop_k = 20\nbaseline_sql = f\"\"\"\nSELECT base.content AS query,\n       query.product_id,\n       LEFT(query.content, 70) AS product_details,\n       distance AS cosine_distance,\n        (CASE \n        WHEN query.esci_label = \"E\" THEN \"Exact\"\n        WHEN query.esci_label = \"S\" THEN \"Substitute\"\n        WHEN query.esci_label = \"C\" THEN \"Complement\"\n        WHEN query.esci_label = \"I\" THEN \"Irrelevant\"\n       END\n       ) AS esci_label,\n       (CASE \n        WHEN query.esci_label = \"E\" THEN 1\n        WHEN query.esci_label = \"S\" THEN 0.1\n        WHEN query.esci_label = \"C\" THEN 0.01\n        WHEN query.esci_label = \"I\" THEN 0\n       END\n       ) AS relevance\nFROM\nVECTOR_SEARCH(\n  (SELECT * \n   FROM `graphite-cell-472319-d2.amazon_esci.query_embeddings` \n   WHERE content = \"{search_text}\"),\n  'ml_generate_embedding_result',\n  (SELECT product_id, \n          content,\n          ml_generate_embedding_result,\n          esci_label\n  FROM `graphite-cell-472319-d2.amazon_esci.product_embeddings`\n  JOIN `graphite-cell-472319-d2.amazon_esci.shopping_queries_dataset_examples` USING (product_id)\n  WHERE TRUE\n    AND product_locale = \"us\"\n    AND query = \"{search_text}\"\n    AND small_version = 1),\n  'ml_generate_embedding_result',\n  top_k => {top_k}\n)  \nORDER BY distance\nLIMIT {top_k}\n\n\"\"\"\nquery_job = client.query(baseline_sql)\nbaseline_results = query_job.result().to_dataframe()\n\nprint(\"ðŸ”¹ Baseline Vector Search Results\")\ndisplay(baseline_results)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T22:33:31.041179Z","iopub.execute_input":"2025-09-19T22:33:31.042002Z","iopub.status.idle":"2025-09-19T22:33:32.291646Z","shell.execute_reply.started":"2025-09-19T22:33:31.041970Z","shell.execute_reply":"2025-09-19T22:33:32.290200Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Sample search run on centroid vectors","metadata":{}},{"cell_type":"code","source":"from google.cloud import bigquery\n\nclient = bigquery.Client(project=\"graphite-cell-472319-d2\")\n\n# hardcoded query for testing purposes\nsearch_text = \"rc drone without camera\"\n\n# return top 20 search results\ntop_k = 20\ncentroid_sql = f\"\"\"\nSELECT base.query,\n       query.product_id,\n       LEFT(query.content, 70) AS product_details,\n       distance AS cosine_distance,\n        (CASE \n        WHEN query.esci_label = \"E\" THEN \"Exact\"\n        WHEN query.esci_label = \"S\" THEN \"Substitute\"\n        WHEN query.esci_label = \"C\" THEN \"Complement\"\n        WHEN query.esci_label = \"I\" THEN \"Irrelevant\"\n       END\n       ) AS esci_label,\n       (CASE \n        WHEN query.esci_label = \"E\" THEN 1\n        WHEN query.esci_label = \"S\" THEN 0.1\n        WHEN query.esci_label = \"C\" THEN 0.01\n        WHEN query.esci_label = \"I\" THEN 0\n       END\n       ) AS relevance\nFROM\nVECTOR_SEARCH(\n  (SELECT * \n   FROM `graphite-cell-472319-d2.amazon_esci.centroid_vectors` \n   WHERE query = \"{search_text}\"),\n  'centroid',\n  (SELECT product_id, \n          content,\n          ml_generate_embedding_result,\n          esci_label\n  FROM `graphite-cell-472319-d2.amazon_esci.product_embeddings`\n  JOIN `graphite-cell-472319-d2.amazon_esci.shopping_queries_dataset_examples` USING (product_id)\n  WHERE TRUE\n    AND product_locale = \"us\"\n    AND query = \"{search_text}\"\n    AND small_version = 1),\n  'ml_generate_embedding_result',\n  top_k => {top_k}\n)  \nORDER BY distance\nLIMIT {top_k}\n\n\n\"\"\"\nquery_job = client.query(centroid_sql)\ncentroid_results = query_job.result().to_dataframe()\n\nprint(\"ðŸ”¹ Centroid Vector Search Results\")\ndisplay(centroid_results)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-19T22:33:38.442440Z","iopub.execute_input":"2025-09-19T22:33:38.442805Z","iopub.status.idle":"2025-09-19T22:33:39.793569Z","shell.execute_reply.started":"2025-09-19T22:33:38.442779Z","shell.execute_reply":"2025-09-19T22:33:39.792374Z"}},"outputs":[],"execution_count":null}]}